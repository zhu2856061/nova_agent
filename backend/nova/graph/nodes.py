# -*- coding: utf-8 -*-
# @Time   : 2025/04/01 10:24
# @Author : zip
# @Moto   : Knowledge comes from decomposition
import json
import logging
import time
import uuid
from typing import Literal

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from nova import CONF
from nova.graph.agents import research_agent
from nova.graph.configuration import Configuration
from nova.graph.mstate import OverallState
from nova.graph.template import apply_system_prompt_template
from nova.llms import get_llm_by_type
from nova.tools import (
    create_directory_tool,
    handoff_to_planner,
    read_json_tool,
    serp_tool,
    write_file_tool,
    write_json_tool,
)
from nova.utils import repair_json_output, set_color

logger = logging.getLogger(__name__)


def write_to_log(node, response, task_dir, appended=False):
    current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    _tmp = {"current_time": current_time, "node": node, "node_output": response}
    _tmp = json.dumps(_tmp, ensure_ascii=False) + "\n"
    write_file_tool.run(
        {
            "file_path": f"{task_dir}/log.jsonl",
            "text": _tmp,
            "append": appended,
        },
    )


# ğŸŒŸ
def coordinator_node(
    state: OverallState,
    config: RunnableConfig,
) -> Command[Literal["planner", "__end__"]]:
    """åè°ƒå‘˜å°†ä»»åŠ¡åˆ†é…ç»™ä¸åŒçš„å›¢é˜Ÿï¼Œæ¯ä¸ªå›¢é˜ŸåŒ…å«ã€Œç®¡ç†å‘˜*1 è®¡åˆ’è€…*0/1 æ‰§è¡Œè€…* Nã€"""
    configurable = Configuration.from_runnable_config(config)
    if configurable.task_id == "":
        configurable.task_id = str(uuid.uuid4())
    _task = configurable.task_id
    _task_dir = CONF["SYSTEM"]["TASK_DIR"] + "/" + _task
    _model_name = configurable.coordinator_model

    def _assemble_prompt():
        """
        ç»„è£…æˆæç¤º system message + user message
        SystemMessage + HumanMessage[question]
        """
        if state["messages"] is None:
            return "__end__"
        system_messages = apply_system_prompt_template("coordinator", state)

        all_messages = system_messages + state["messages"]
        return all_messages

    def _execute_llm(messages):
        """
        æ‰§è¡ŒLLM - åŸºäºLLMçš„æ„å›¾è¯†åˆ«ï¼Œ æœªæ¥æœ‰æ›´å¥½çš„æ„å›¾è¯†åˆ«ï¼ˆé‡‡ç”¨handoff_to_plannerå·¥å…·æ‰¿æ¥ï¼‰ï¼‰
        """
        response = (
            get_llm_by_type(_model_name)
            .bind_tools([handoff_to_planner])
            .invoke(messages)
        )
        response.name = "coordinator"
        write_to_log("coordinator", response.model_dump(), _task_dir)
        return response

    try:
        logger.info(
            set_color(f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Coordinatorã€‘ - Activate. ", "pink")
        )
        # 1 åˆ›å»ºä»»åŠ¡æ–‡ä»¶å¤¹
        _task_dir = create_directory_tool.run(_task_dir)

        # 2 æ„å»ºprompt
        messages = _assemble_prompt()
        if messages is None:
            return Command(
                goto="__end__",
                update={
                    "messages": [
                        AIMessage(content="question is None", name="coordinator")
                    ]
                },
            )
        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Coordinatorã€‘ - ã€assemble_promptã€‘\n {messages}",
                "pink",
            )
        )

        # 3 æ‰§è¡ŒLLMæ„å›¾è¯†åˆ«
        response = _execute_llm(messages)
        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Coordinatorã€‘ - ã€execute_llmã€‘\n {response}",
                "pink",
            )
        )

        # 4 å†³å®šä¸‹ä¸€æ­¥
        goto = "__end__"
        if len(response.tool_calls) > 0:  # type: ignore
            goto = "planner"

        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Coordinatorã€‘ - ã€delegatingã€‘\n to {goto}",
                "pink",
            )
        )
        if goto == "__end__":
            return Command(
                goto=goto,
                update={
                    "answer": [AIMessage(content=response.content, name="coordinator")]
                },
            )
        else:
            return Command(
                goto=goto, update={"question": state["messages"][-1].content}
            )
    except Exception as e:
        _tmp = f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Coordinatorã€‘ - ã€Exceptionã€‘ failed: {e}"
        logger.error(set_color(_tmp, "red"))
        return Command(
            goto="__end__",
            update={"answer": AIMessage(content=_tmp, name="coordinator")},
        )


# ğŸŒŸ
def planner_node(
    state: OverallState,
    config: RunnableConfig,
) -> Command[Literal["supervisor", "__end__"]]:
    """:è®¡åˆ’è€…
    plan çš„å†…å®¹æ ¼å¼å¦‚ä¸‹ï¼š
    {
        "thought": str,
        "title": str,
        "steps": [
            {
                "state": "todo",
                "retry_count": 0,
                "agent_name": "researcher",
                "title": str,
                "description": str
            }
        ]
    }
    """
    configurable = Configuration.from_runnable_config(config)
    _task = configurable.task_id

    _task_dir = CONF["SYSTEM"]["TASK_DIR"] + "/" + _task
    _model_name = configurable.planner_model
    _is_serp_before_planning = configurable.is_serp_before_planning
    _is_deep_thinking_mode = configurable.is_deep_thinking_mode

    def _serp_before_planning(query) -> str:
        """åœ¨è®¡åˆ’å‰å…ˆè¿›è¡Œä¸€æ¬¡serpæœç´¢"""
        try:
            searched_content = serp_tool.run({"query": query})
            _tmp = []
            for elem in searched_content:
                title = elem["title"]
                content = elem["content"]
                _tmp.append(f"- **title**: {title}, **content**: {content}")
            _tmp = "\n".join(_tmp)
            return _tmp
        except Exception as e:
            logger.error(
                f"search before planning failed : {searched_content}, error: {e}"
            )
            return ""

    def _assemble_prompt():
        """ç»„è£…æˆæç¤º
        SystemMessage
        HumanMessage -> Relative Search Results: [serp content] + [question]
        """
        system_messages = apply_system_prompt_template("planner", state)
        question = state.get("question", None)
        if question is None or question == "":
            return None

        tmp = f"Question: {question}"
        if _is_serp_before_planning:
            searched_content = _serp_before_planning(question)
            if searched_content != "":
                tmp = f"\n\n# Relative Search Results:\n\n{searched_content} \n\n {tmp}"

        messages = system_messages + [HumanMessage(content=tmp)]
        return messages

    def _execute_llm(messages):
        """æ‰§è¡ŒLLM"""
        llm = get_llm_by_type(_model_name)
        if _is_deep_thinking_mode:
            llm = get_llm_by_type("REASONING")

        _response = llm.invoke(messages)
        _response.name = "planner"
        write_to_log("planner", _response.model_dump(), _task_dir, appended=True)
        return _response

    def _output_handle(response):
        try:
            _response = repair_json_output(str(response.content))
            # å°†æ•°æ®è½¬æ¢æˆtodo list
            _response = json.loads(_response)
            steps = _response["steps"]
            thought = _response["thought"]
            title = _response["title"]

            # åˆå§‹åŒ–çŠ¶æ€å’Œé‡è¯•æ¬¡æ•°
            for i, step in enumerate(steps):
                step["status"] = "TODO"
                step["retry_count"] = 0
            result = {"title": title, "thought": thought, "steps": steps}

            # å°†è®¡åˆ’å†™å…¥è®¡åˆ’ä¹¦ä¸­
            write_json_tool.run(
                {
                    "file_path": f"{_task_dir}/plan.jsonl",
                    "jsonl": result,
                }
            )
            logger.info(f"<<<<<<< ã€{_task}ã€‘ plan write in {_task_dir}/plan")
            return result
        except Exception:
            return None

    # -- è®¡åˆ’é‡è¯•
    try:
        logger.info(
            set_color(f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Planerã€‘ - Activate. ", "pink")
        )
        messages = _assemble_prompt()
        if messages is None:
            return Command(
                goto="__end__",
                update={
                    "messages": [AIMessage(content="question is None", name="planner")]
                },
            )
        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Planerã€‘ - ã€assemble_promptã€‘\n {messages}",
                "pink",
            )
        )
        _response = _execute_llm(messages)
        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Planerã€‘ - ã€execute_llmã€‘\n {_response}",
                "pink",
            )
        )
        _response = _output_handle(_response)

        goto = "supervisor"
        if _response is None:
            goto = "__end__"

        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Planerã€‘ - ã€output_handleã€‘\n {_response}",
                "pink",
            )
        )
        if goto == "__end__":
            return Command(
                goto=goto,
                update={
                    "answer": [
                        AIMessage(
                            content="planner err: planner not json ", name="coordinator"
                        )
                    ]
                },
            )
        else:
            return Command(
                goto=goto,
                update={"answer": AIMessage(content=[_response], name="planner")},  # type: ignore
            )

    except Exception as e:
        _tmp = f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Planerã€‘ - ã€Exceptionã€‘\n {e}"
        logger.error(set_color(_tmp, "red"))
        return Command(
            goto="__end__",
            update={"answer": AIMessage(content=_tmp, name="planner")},
        )


# ğŸŒŸ
def supervisor_node(
    state: OverallState,
    config: RunnableConfig,
) -> Command[Literal["researcher", "reporter", "__end__"]]:
    """ç®¡ç†è€…
        1 æ‹¿å‡ºè®¡åˆ’ä¹¦ï¼ŒæŒ‰ç…§è®¡åˆ’ä¸­çš„stepsé€æ­¥æ‰§è¡Œï¼Œä¸‹å‘ç»™å…·ä½“çš„agent_nameè¿›è¡Œæ‰§è¡Œ
        2 è·å–agent_nameçš„è¿”å›ç»“æœï¼Œå¹¶è¿›è¡ŒéªŒæ”¶ï¼ˆéœ€è¦æ€è€ƒï¼‰å¹¶æ›´æ–°stateå­—æ®µ

    éªŒæ”¶ç»“æœæœ‰ä¸‰ç§ï¼š
        1 è‹¥æ»¡æ„åˆ™æ›´æ–°stateå­—æ®µä¸º**DONE**
        2 è‹¥ä¸æ»¡æ„ä¸”retry_count<è®¾å®šçš„é˜ˆå€¼åˆ™æ›´æ–°stateå­—æ®µä¸º**TODO** , å¹¶è¦æ±‚ç»§ç»­æ‰§è¡Œè¯¥æ­¥éª¤
        3 è‹¥ä¸æ»¡æ„ä¸”retry_count>è®¾å®šçš„é˜ˆå€¼æ›´æ–°stateå­—æ®µä¸º**Failed** , å¹¶ç»“æŸä»»åŠ¡
    """
    configurable = Configuration.from_runnable_config(config)
    _task = configurable.task_id
    _task_dir = CONF["SYSTEM"]["TASK_DIR"] + "/" + _task
    _model_name = configurable.supervisor_model
    _retry_limit = configurable.retry_limit

    def _read_plan():
        plan = read_json_tool.run({"file_path": f"{_task_dir}/plan.jsonl"})
        return plan

    def _assemble_prompt(plan, current_task, current_result):
        """ç»„è£…æˆæç¤º
        SystemMessage
        HumanMessage -> Plan: [question] + [plan]
        """
        tmp = f"## æ•´ä½“è®¡åˆ’ \n {plan} \n\n ## å½“å‰ä»»åŠ¡ \n {current_task} \n\n ## å½“å‰ä»»åŠ¡çš„ç»“æœ \n {current_result} \n"
        system_messages = apply_system_prompt_template("supervisor", state)
        messages = system_messages + [HumanMessage(content=tmp)]

        return messages

    def _execute_llm(messages):
        """æ‰§è¡ŒLLM"""
        response = get_llm_by_type(_model_name).invoke(messages)
        write_to_log("supervisor", response.model_dump(), _task_dir, appended=True)
        return response

    def _output_handle(response):
        _response = response.content
        _response = repair_json_output(str(_response))
        _response = json.loads(_response)
        return _response

    def _acceptance_agent_result(plan, step, result):
        """å–å‡ºè®¡åˆ’å¹¶è¿›è¡Œæ›´æ–°"""
        _current_step = step
        _current_task = plan.get("steps", [])[_current_step]
        _retry_count = _current_task.get("retry_count", 0)

        _messages = _assemble_prompt(plan, _current_task, result)
        response = _execute_llm(_messages)
        response = _output_handle(response)
        if response["acceptance"] == "ACCEPT":
            _current_task["status"] = "DONE"
            _current_task["result"] = result
            _current_step += 1

        elif response["acceptance"] == "REJECT" and _retry_count < _retry_limit:
            _reason = response.get("reason")
            _current_task["status"] = "TODO"
            _current_task["fail_reason"] = _reason or "Unknown"
            _current_task["retry_count"] = _retry_count + 1

        else:
            _current_task["status"] = "FAIL"
            _current_step = float("inf")

        write_json_tool.invoke(
            {
                "file_path": f"{_task_dir}/plan.jsonl",
                "jsonl": plan,
            }
        )

        return _current_step

    # åŸºäºè®¡åˆ’ï¼Œé€‰æ‹©agent
    try:
        logger.info(
            set_color(f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - Activate. ", "pink")
        )

        _answer = state["answer"]
        _plan = _read_plan()
        if _answer.name == "planner" and len(_plan.get("steps", [])) > 0:
            _step = 0
            _step_info = _plan["steps"][_step]
            goto = _step_info.get("agent_name", "__end__")
            logger.info(
                set_color(
                    f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - ã€delegatingã€‘ to: {goto}",
                    "pink",
                )
            )
            return Command(goto=goto, update={"step": _step})

        elif _answer.name != "planner" and len(_plan.get("steps", [])) > 0:
            _step = state.get("step", 0)
            _answer = state["answer"]

            _step = _acceptance_agent_result(_plan, _step, _answer.content)

            if _step >= len(_plan["steps"]):
                goto = "__end__"
                logger.info(
                    set_color(
                        f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - ã€delegatingã€‘ to: {goto}",
                        "pink",
                    )
                )
                return Command(goto=goto, update={"messages": [_answer]})

            _step_info = _plan["steps"][_step]
            goto = _step_info.get("agent_name", "__end__")
            logger.info(
                set_color(
                    f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - ã€delegatingã€‘ to: {goto}",
                    "pink",
                )
            )
            return Command(goto=goto, update={"step": _step})

        else:
            goto = "__end__"
            logger.info(
                set_color(
                    f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - ã€delegatingã€‘ to: {goto}",
                    "pink",
                )
            )
            return Command(goto=goto)

    except Exception as e:
        _tmp = f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Supervisorã€‘ - ã€Exceptionã€‘ failed: {e}"
        logger.error(set_color(_tmp, "red"))
        return Command(
            goto="__end__",
            update={"answer": AIMessage(content=_tmp, name="supervisor")},
        )


# ğŸŒŸ
def researcher_node(
    state: OverallState,
    config: RunnableConfig,
) -> Command[Literal["supervisor"]]:
    """Node for the researcher agent that performs research tasks.
    ## æ•´ä½“è®¡åˆ’
    ## å½“å‰ä»»åŠ¡

    """
    configurable = Configuration.from_runnable_config(config)
    _task = configurable.task_id
    _task_dir = CONF["SYSTEM"]["TASK_DIR"] + "/" + _task
    _step = state.get("step")

    def _assemble_prompt():
        """ç»„è£…æˆæç¤º
        HumanMessage -> [æ•´ä½“è®¡åˆ’] + [å½“å‰ä»»åŠ¡]
        # - æ•´ä½“è®¡åˆ’
        # - å½“å‰ä»»åŠ¡
        """
        # æ•´ä½“è®¡åˆ’
        _plan = read_json_tool.run(
            {
                "file_path": f"{_task_dir}/plan.jsonl",
            }
        )

        # å½“å‰ä»»åŠ¡
        _current_task = _plan["steps"][_step]
        _messages = [
            HumanMessage(
                content=f"## æ•´ä½“è®¡åˆ’ \n {_plan} \n\n ## å½“å‰ä»»åŠ¡ \n {_current_task}"
            )
        ]

        return {"messages": _messages}

    # æ‰§è¡ŒLLM
    def _execute_llm(messages):
        _response = research_agent.invoke(messages)

        _tmp = [message.model_dump() for message in _response["messages"]]
        write_to_log("Researcher", _tmp, _task_dir, appended=True)

        return _response

    # è¾“å‡ºå¤„ç†
    def _output_handle(response):
        _response = response["messages"][-1].content
        _response = repair_json_output(str(_response))
        return _response

    try:
        logger.info(
            set_color(f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Researcherã€‘ - Activate. ", "pink")
        )
        _agent_state = _assemble_prompt()
        _response = _execute_llm(_agent_state)
        _response = _output_handle(_response)

        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Researcherã€‘ - ã€delegatingã€‘ to: supervisor",
                "pink",
            )
        )
        return Command(
            update={"answer": AIMessage(content=_response, name="researcher")},
            goto="supervisor",
        )

    except Exception as e:
        _tmp = f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Researcherã€‘ - ã€Exceptionã€‘ failed: {e}"
        logger.error(set_color(_tmp, "red"))
        return Command(
            goto="supervisor",
            update={
                "success": False,
                "answer": AIMessage(content=_tmp, name="researcher"),
            },
        )


# ğŸŒŸ
def reporter_node(
    state: OverallState,
    config: RunnableConfig,
) -> Command[Literal["supervisor"]]:
    """Reporter node that write a final report.
    ## æ•´ä½“è®¡åˆ’
    ## å½“å‰ä»»åŠ¡
    """
    configurable = Configuration.from_runnable_config(config)
    _task = configurable.task_id
    _task_dir = CONF["SYSTEM"]["TASK_DIR"] + "/" + _task
    logger.info(f">>>>>>> ã€{_task}ã€‘ ->Reporter<- Activate. ")
    _model_name = configurable.reporter_model

    _step = state.get("step")

    def _assemble_prompt():
        """ç»„è£…æˆæç¤º
        SystemMessage
        HumanMessage -> [æ•´ä½“è®¡åˆ’] + [å½“å‰ä»»åŠ¡]
        # - æ•´ä½“è®¡åˆ’
        # - å½“å‰ä»»åŠ¡
        """
        system_messages = apply_system_prompt_template("reporter", state)
        # æ•´ä½“è®¡åˆ’
        _plan = read_json_tool.run(
            {
                "file_path": f"{_task_dir}/plan.jsonl",
            }
        )
        # å½“å‰ä»»åŠ¡
        _current_task = _plan["steps"][_step]
        _messages = f"## æ•´ä½“è®¡åˆ’ \n {_plan} \n\n ## å½“å‰ä»»åŠ¡ \n {_current_task}"

        return system_messages + [HumanMessage(content=_messages)]

    # æ‰§è¡ŒLLM
    def _execute_llm(messages):
        _response = get_llm_by_type(_model_name).invoke(messages)
        write_to_log("reporter", _response.model_dump(), _task_dir, appended=True)
        return _response

    # è¾“å‡ºå¤„ç†
    def _output_handle(response):
        _response = repair_json_output(str(response.content))
        return _response

    try:
        logger.info(
            set_color(f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Reporterã€‘ - Activate. ", "pink")
        )
        messages = _assemble_prompt()
        _response = _execute_llm(messages)
        _response = _output_handle(_response)

        logger.info(
            set_color(
                f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Reporterã€‘ - ã€delegatingã€‘ to: supervisor",
                "pink",
            )
        )
        return Command(
            update={
                "answer": AIMessage(content=_response, name="reporter"),
            },
            goto="supervisor",
        )
    except Exception as e:
        _tmp = f"ğŸ“¡ >>>>>>> ã€{_task}ã€‘ - ã€Reporterã€‘ - ã€Exceptionã€‘ failed: {e}"
        logger.error(set_color(_tmp, "red"))
        return Command(
            goto="supervisor",
            update={
                "success": False,
                "answer": AIMessage(content=_tmp, name="reporter"),
            },
        )
