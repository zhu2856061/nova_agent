SYSTEM:
  IP_PORT: "0.0.0.0:2021"
  WORKERS: 2
  TIMEOUT: 1800

  log_dir: "./logs"
  env_path: "./env"
  task_dir: $TASK_DIR
  cache_dir: "./cache"
  prompt_template_dir: $PROMPT_PATH

LLM:
  - model_name: "basic"
    litellm_params:
      model: "openai/Qwen3-235B-A22B"
      api_base: $LEXIN_LLM_URL
      api_key: $LEXIN_LLM_API_KEY
      cache: true
      verbose: true
      request_timeout: 600
      temperature: 0.2
      top_p: 0.2
      max_retries: 2

  - model_name: "reasoning"
    litellm_params:
      model: "openai/Qwen3-235B-A22B"
      api_base: $LEXIN_LLM_URL
      api_key: $LEXIN_LLM_API_KEY
      cache: true
      verbose: true
      request_timeout: 600
      temperature: 0.2
      top_p: 0.2
      top_k: 10
      max_retries: 2

  - model_name: "basic_no_thinking"
    litellm_params:
      model: "openai/Qwen3-235B-A22B"
      api_base: $LEXIN_LLM_URL
      api_key: $LEXIN_LLM_API_KEY
      cache: true
      verbose: true
      request_timeout: 600
      temperature: 0.2
      top_p: 0.2
      top_k: 10
      max_retries: 2
      chat_template_kwargs:
         enable_thinking: false # 关闭思考模式

  - model_name: "deepseek"
    litellm_params:
      model: "deepseek/deepseek-chat"
      api_base: $DEEPSEEK_URL
      api_key: $DEEPSEEK_API_KEY
      cache: true
      verbose: true
      request_timeout: 600
      temperature: 0.2
      top_p: 0.2
      top_k: 10
      max_retries: 2

  - model_name: "gemini"
    litellm_params:
      model: "openai/gemini-2.0-flash"
      api_base: $GEMINI_URL
      api_key: $GEMINI_API_KEY
      cache: true
      verbose: true
      request_timeout: 600
      temperature: 0.2
      top_p: 0.2
      top_k: 10
      max_retries: 2