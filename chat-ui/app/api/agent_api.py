import json
import logging
import uuid

import httpx
import requests

# åç«¯æ¥å£åœ°å€
STREAM_AGENT_MEMORIZER_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/memorizer"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)
STREAM_AGENT_RESEARCHER_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/researcher"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)
STREAM_AGENT_WECHATRESEARCHER_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/wechat_researcher"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)
STREAM_AGENT_AINOVEL_ARCHITECT_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/ainovel_architect"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)
STREAM_AGENT_AINOVEL_CHAPTER_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/ainovel_chapter"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)

HUMAN_IN_LOOP_BACKEND_URL = "http://0.0.0.0:2021/agent/human_in_loop"

AGENT_AINOVEL_EXTRACT_SETTING_BACKEND_URL = (
    "http://0.0.0.0:2021/agent/ainovel_extract_setting"  # éœ€æ ¹æ®å®é™…ä¿®æ”¹
)
logger = logging.getLogger(__name__)


async def get_agent_api(
    url: str,
    trace_id: str,
    state: dict,  # {"memorizer_messages": messages}
    context: dict,
    user_guidance: dict,
    stream=True,
):
    trace_id = trace_id or str(uuid.uuid4())

    request_data = {
        "trace_id": trace_id,
        "context": context,
        "state": state,  # {"memorizer_messages": messages}
        "user_guidance": user_guidance,
        "stream": stream,
    }

    current_answer_message_id = None
    current_reasoning_message_id = None

    try:
        async with httpx.AsyncClient() as client:
            # å‘é€ POST è¯·æ±‚åˆ° /stream_llm è·¯ç”±
            async with client.stream(
                "POST", url, json=request_data, timeout=3600.0
            ) as response:
                response.raise_for_status()

                async for chunk in response.aiter_bytes():
                    if not chunk:
                        continue

                    try:
                        line_data = json.loads(chunk.decode("utf-8"))

                        if line_data.get("code", 1) != 0:
                            error_msg = f"âŒ åç«¯é”™è¯¯: {line_data.get('message', 'æœªçŸ¥é”™è¯¯')}(code={line_data.get('code')})"
                            logger.error(f"{error_msg} (trace_id: {trace_id})")
                            yield {"type": "error", "content": error_msg}
                            return

                        _event = line_data["messages"]["event"]
                        _data = line_data["messages"]["data"]
                        _node_name = _data["node_name"]
                        _step = _data["step"] or 0

                        # ç³»ç»Ÿäº‹ä»¶
                        if _event in [
                            "on_chain_start",
                            "on_chain_end",
                            "on_tool_start",
                            "on_tool_end",
                        ]:
                            if _event == "on_chain_start":
                                _graph_name = _node_name.split("|")[0]
                                if "RunnableSequence" in _node_name:
                                    content = None
                                elif "LangGraph" in _node_name:
                                    if _graph_name:
                                        content = f"â³ ã€å›¾{_graph_name}ã€‘å¼€å§‹ä»»åŠ¡\n\n"
                                    else:
                                        content = "â³ ã€å›¾taskã€‘å¼€å§‹ä»»åŠ¡\n\n"
                                else:
                                    content = f"ğŸ“Œ ã€å›¾{_graph_name}ã€‘ğŸš€ã€ç¬¬{_step}æ­¥æ‰§è¡Œ: {_node_name}ã€‘\n\n"

                            elif _event == "on_chain_end":
                                _graph_name = _node_name.split("|")[0]
                                if "RunnableSequence" in _node_name:
                                    content = None
                                elif "LangGraph" in _node_name:
                                    if _graph_name:
                                        content = f"âœ… ã€å›¾{_graph_name}ã€‘ ğŸŸ¢ ã€ä»»åŠ¡ç»“æŸã€‘\n\n"
                                    else:
                                        content = "âœ… ã€å›¾taskã€‘ ğŸŸ¢ ã€ä»»åŠ¡ç»“æŸã€‘\n\n"
                                else:
                                    content = f"â³ ã€å›¾{_graph_name}ã€‘ğŸŸ¢ã€ç¬¬{_step}æ­¥å®Œæˆã€‘: {_node_name}\n\n"

                            elif _event == "on_tool_start":
                                _input = str(_data["input"])
                                content = (
                                    f"ğŸ› ï¸ ã€è°ƒç”¨å·¥å…·: {_node_name}ã€‘\n\nå…¥å‚: {_input[:200]}...\n\n"
                                    if len(_input) > 200
                                    else f"ğŸ› ï¸ ã€è°ƒç”¨å·¥å…·: {_node_name}ã€‘\n\nå…¥å‚: {_input}\n\n"
                                )

                            elif _event == "on_tool_end":
                                _output = str(_data["output"])
                                content = (
                                    f"ğŸ› ï¸ ã€å·¥å…·: {_node_name}æ‰§è¡Œç»“æŸã€‘\n\nå‡ºå‚: {_output[:200]}...\n\n"
                                    if len(_output) > 200
                                    else f"ğŸ› ï¸ ã€å·¥å…·: {_node_name}æ‰§è¡Œç»“æŸã€‘\n\nå‡ºå‚: {_output}\n\n"
                                )

                            if content:
                                yield {"type": "system", "content": content}

                        elif _event in [
                            "on_chat_model_start",
                            "on_chat_model_end",
                            "on_chat_model_stream",
                        ]:
                            if _event == "on_chat_model_start":
                                content = f"ğŸ¤” ã€{_node_name}: æ­£åœ¨æ€è€ƒ...ã€‘\n\n"
                                if content:
                                    yield {"type": "chat_start", "content": content}

                            elif _event == "on_chat_model_end":
                                # title = f"âœ¨ ã€{_node_name}: æ€è€ƒå®Œæˆã€‘\n\n"
                                reasoning_content = (
                                    _data["output"].get("reasoning_content", "").strip()
                                )
                                content = _data["output"].get("content", "").strip()
                                tool_calls = _data["output"].get("tool_calls", [])

                                key_info = {
                                    "content": content,
                                    "reasoning_content": reasoning_content,
                                    "tool_calls": tool_calls,
                                }

                                yield {"type": "chat_end", "content": key_info}

                            # æ¨¡å‹æµå¼äº‹ä»¶ - åŒºåˆ†æ€è€ƒå’Œå›ç­”å†…å®¹
                            elif _event == "on_chat_model_stream":
                                _output = _data["output"]
                                _message_id = _output["message_id"]
                                _reasoning = _output.get("reasoning_content", "")
                                _answer = _output.get("content", "")
                                # _tool_calls = _output.get("tool_calls", [])

                                # æ€è€ƒå†…å®¹
                                if _reasoning:
                                    if _message_id != current_reasoning_message_id:
                                        current_reasoning_message_id = _message_id
                                        yield {
                                            "type": "thought",
                                            "content": "\n\nğŸ“ æ€è€ƒè¿‡ç¨‹ï¼š\n\n",
                                        }

                                    yield {
                                        "type": "thought",
                                        "content": f"{_reasoning}",
                                    }

                                # å›ç­”å†…å®¹
                                if _answer:
                                    if _message_id != current_answer_message_id:
                                        current_answer_message_id = _message_id
                                        yield {
                                            "type": "answer",
                                            "content": "\n\nğŸ“Œ å›ç­”å†…å®¹ï¼š\n\n",
                                        }

                                    yield {"type": "answer", "content": f"{_answer}"}

                        elif _event in ["on_chain_stream"]:
                            _output = _data["output"]
                            _content = _output.get("content", "")
                            yield {
                                "type": "human_in_loop",
                                "content": f"\n\nğŸ äººå·¥ä»‹å…¥ï¼š{_content}\n\n",
                            }

                    except json.JSONDecodeError:
                        error_msg = f"âŒ å“åº”æ ¼å¼é”™è¯¯: æ— æ³•è§£æå†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰: {chunk[:200]}..."
                        logger.error(f"{error_msg} (trace_id: {trace_id})")
                        yield {"type": "error", "content": error_msg}
                        return
                    except KeyError as e:
                        error_msg = f"âŒ å“åº”ç»“æ„é”™è¯¯: ç¼ºå°‘å¿…è¦å­—æ®µã€Œ{str(e)}ã€"
                        logger.error(f"{error_msg} (trace_id: {trace_id})")
                        yield {"type": "error", "content": error_msg}
                        return

    except requests.exceptions.RequestException as e:
        error_msg = f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}ï¼ˆæµå¼è¿æ¥ä¸­æ–­ï¼‰"
        logger.error(f"{error_msg} (trace_id: {trace_id})")
        yield {"type": "error", "content": error_msg}
        return
    except Exception as e:
        error_msg = f"âŒ æµå¼å¤„ç†å¼‚å¸¸: {str(e)}"
        logger.error(f"{error_msg} (trace_id: {trace_id})")
        yield {"type": "error", "content": error_msg}
        return
